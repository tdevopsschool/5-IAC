# 1. IaC Introduction

## 1.1 Configuration management
### 1.1.1 Before Configuration management

Давайте предствим как создается инфраструктура для проекта, с точки зрения специалиста по конфигурации ПО, или разработчика, которому, например, поручили такое дело в отсуствии специалиста по конфигурации ПО в команде : ему необходимо развернуть приложение и для этого нужен сервер. 

![Before configuration management](../assets/01_06.png?raw=true "Before configuration management")

Он звонит в техподдержку или открывает тикет в системе сервисдеск и просит, что ему нужен новый сервер и учетные данные для подключения к нему. В техподдержке системный администратор получает со склада сервер, распаковывает его, устанавливает в серверную, разворачивает ОС на нем и предоставляет доступ для нашего специалиста. Теперь DevOps инженер может подключиться серверу с только что установленной ОС и начать установку, например пакетов системного и прикладного ПО, нужных версий, (Python, Java, Node, PHP, composer) для сервера приложений, или если это сервер БД, то нужные пакеты для Базы определенной версии,  и вручную скопирует уже имеющиеся конфигурационные файлы на эти сервера. которые необходимы для работы разрабатываемого приложения.

![Before configuration management](../assets/01_07.png?raw=true "Before configuration management")

И в этоге наши сервера превраются в условно говоря, снежинку! Невоспроизводимою, уникальную конфигурацию инфраструктуры, которая при каждом последующем создании будет неповторима. Обьяснить это можно многими причинами, например, человеческим фактором, последующее создание такой инфраструктуры может быть выполнено другим системным администратором, который вроде бы и действует по инструкции, но в силу своей загруженности и мультизадачности, в следующий раз установит ОС с версией немного другой, системное ПО, может быть так же других версий, или вовсе отсутствовать, наш специлист, может не обратить на это внимание, и сам выполнить немного другую последовательность действий в процессе ручной конфигурации ПО. 
CM решает эту проблему со сложностями в воспроизведении конфигурацией.

### 1.1.2 Configuration management

Начнем с небольшого примера, зачем нужен СМ, Например у нас есть в проекте build сервер, с помощью которого мы собираем пакет для последующей установки на STAGE Environment. Пусть это будет веб приложение на PHP  

![Сonfiguration management](../assets/01_19.png?raw=true "Сonfiguration management")
 
Этот сервер во время билда берет код из репозитория проекта, скачивает из интернета зависимости и библиотеки необходимые для нового функционала в проекте, создает архив, который в дальнейшем отправляется на Stage окружение и разворачивается там для финального тестирования перед выходом в продакшон.

![Сonfiguration management](../assets/01_23.png?raw=true "Сonfiguration management")

Однажды выясняется, что нам нужно переехать на новую платформу инфраструктуры, по тем или иным причинам, например для того, чтобы расширить возможности нашего CICD процесса, мы получаем доступ к новой инфраструктуре, решаем переехать. Создаем заново Build-сервер или используем одним из уже имеющихся там расшаренных серверов, с вроде-бы такими же параметрами, 

![Сonfiguration management](../assets/01_25.png?raw=true "Сonfiguration management")

но что-то идет не так. Знания о том, как мы 3 года назад устанавливали наш Build-сервер оказались не документированы, версии установленной OS и необходимых пакетов для Build-сервера не совпали, или некоторые пакеты и вовсе отсуствовали.

И как результат - наш сервер оказался неспособным создать Build 

![Сonfiguration management](../assets/01_26.png?raw=true "Сonfiguration management")

СМ – это про то чтобы обеспечить успешный переезд сервера, про то, чтобы знание о конфигурации сервера было актуально и хранилось в репозитории проекта, как например здесь, в Dockerfile и могло быть воспроизведено бестро и без ошибок.

![Сonfiguration management](../assets/01_27.png?raw=true "Сonfiguration management")

СМ – это про такой процесс, который постоянно повторяется, при внесении изменений в конфигурацию, эти изменения документируются, проверяется, что инфраструктура работает, эти знания накапливаются и изучаются совместно в команде, которая работает над созданием приложения.

![Сonfiguration management](../assets/01_29.png?raw=true "Сonfiguration management")

В целом, под инфраструктурой понимают конфигурационные файлы, необходимые для запуска ПО, запущенные сервисы, правила файервола, для предоставления различных доступов, между серверами разработки, в соответствии с политикой безопасности, так же действующие лицензии на платное ПО. 
Задача СМ сводится к тому, чтобы инфраструктура работала и в команде проекта было понимание как это работает. Скорее всего, конечно, не все участники команды обладают этим пониманием, но все знают где можно ознакомиться с подробностями инфраструктуры, и у кого можно проконсультироваться по поводу конфигурации, внутри команды.

И как результат, в работе СМ, вместо снежинки, которая получилась из серверов, при ручной настройке различными специалистами,

![Сonfiguration management](../assets/01_30.png?raw=true "Сonfiguration management")

У нас получилась воспроизводимая конфигурация. Возможно это будет не быстро и не сразу, мы снова будем звонить в техподдержку, чтобы нам установили сервера в стойки, настроили их, но знание об инфраструктуре о том как настроены сервера, в команде известно и хранится, например в вики и мы можем это воспроизвести.

![Сonfiguration management](../assets/01_31.png?raw=true "Сonfiguration management")

### 1.1.3 Infrastructure as Code (IaC)

Как следующий этап развития в СМ появился запрос о том, что нужно воспроизводить инфраструктуру быстрее, и вопрос: что делать в случае, если нужно срочно переехать в новый дата центр,  при этом имающийся датацентр больше недоступен и нам нужно все построить с нуля.

![Сonfiguration management](../assets/01_32.png?raw=true "Сonfiguration management")

И здесь появляется IaC то есть меняется представление о том где хранится знание об инфраструктуре: вместо вики страниц в конфлюенсе или, еще до них, вместо распечаток в больших папках на стелажах, наше знание перемещается в код, который лежит в репозитории с определенным набором инструментов: ПО, например вместо коллцентра техподдержки используется Тарраформ (мы еще будем о нем говорить подробней позже), настройка сервера производится не вручную, вводом команд через удаленное подключение к серверу, а представляется в виде воспроизводимого кода в Ансибл.

Подводя итог определию СМ, можно сказать, что вместо уникальной конфигураций у нас должна быть воспроизводимая рабочая конфигурация, которую можно контролировать и понимать как она работает.

![Сonfiguration management](../assets/01_33.png?raw=true "Сonfiguration management")

## 1.2 IaC: Vagrant, Packer, Terraform, Ansible
### 1.2.1 IaC Intro

СМ, как мы уже говорили, может работать со звонком в техподдержку в датацентр, для того, чтобы нам помогли настроить сервер, и так же может работать, при помощи набора ПО, которое может ускорить управление серверами в датацетре и представить конфигурацию в виде кода.
В обоих вариантах СМ отвечает на вопрос:

![Сonfiguration management](../assets/01_36.png?raw=true "Сonfiguration management")

Как бороться с беспорядком? Как привести инфраструктуру, к тому, чтобы она была воспроизводима.

![Сonfiguration management](../assets/01_41.png?raw=true "Сonfiguration management")

Знание о том, как устроена инфраструктура может храниться в виде тасок в Джире и Вики страниц в конфлюенсе, но 
Тут надо понимать, как это знание, построенное отдельно от самой инфраструктуры, соотносится с тем, что реально происходит в действительности, т.е. на самих серверах, действительно, ли то что описано в вики, применено на серверах сейчас, в данный момент времени, а не на момент написания страницы в вики, или на момет закрытия задачи в джире. Для гротеска, еще можно вспомнить бумажный докментооборот, на предоставление доступа и согласование конфигураций с подписями и печатями, между подразделениями, который еще можно встретить, и сейчас, как основной способ ведения документации во многих крупных компаниях.
В варианте описания инфраструктуры в виде кода, как в правой части слайда, хранящегося в репозитории проекта, нам не нужно беспокоиться об
актуальности этого знания, мы точно уверены, что именно эти версии джавы и БД установлены, для определенной версии приложения в настойщий момент. Нам не нужно специально вручную подключаться к серверам, для того, чтобы в этом убедиться. Конечно для этого у нас должен быть настроен IaC, с помощью специальных инструментов

![Сonfiguration management](../assets/01_42.png?raw=true "Сonfiguration management")

Надо понимать, что инфраструктура описанная с помощью кода, т.е. конфигурационые файлы написанные в разных инструментах и размещенные в репозитории, сами по себе не обеспечат, и не заменят традиционный СМ, необходимо приложить определенное время и силы, для того, чтобы IaC заработал эффективно. О том как это сделать, расскажет Лев в 5 и 6 темах – это будет в следующее занятие, в понедельник. Так же мы говорим об этом в нашем дополнительном, углубленном курсе по Ансибл, разработанный Львом Гончаровым, дающий практические навыки работы с А, как одного из инструментов IaC.

### 1.2.2 IaC use cases

Рассмортим пример, как используется IaC в реальной жизни в проекте

![Сonfiguration management](../assets/01_52.png?raw=true "Сonfiguration management")

Например, в проекте уже есть сервера, при помощи подхода IaC, Можно описать их конфигурацию в виде кода, который размещен в репозитории проекта в гите, в этом случае, если после применения новых конфигурационных файлов, что-то пошло не так, можно вернуться к предыдущей версии файлов в репозитории и восстановить работу окружения для разработки на серверах. При этом не нужно вручную подключаться к каждому серверу и раскоментировать старые резервные копии конфигурационных файлов.
Так же, с помощью IaC можно создавать и вносить изменения в конфигурацию самих виртуальных машин, например, быстро, целиком пересоздать окружение, начать, снова с чистой ОС и виртального диска без лишней врЕменной или созданной по ошибке структуры файлов. 
Еще с помощью IaC можно создавать эталонные шаблоны ВМ, в которые включено все необходимое для развертывания ВМ с разрабатываемым приложением, и как вариант, предоставить такой шаблон для разворачивания у клиента, или для быстрого включения в работу нового разработчика, которому не нужно самостоятельно, по инструкции на вики устанавливать все необходимое для рабочего окружения.
C другой стороны, установка приложения с помощью IaC поможет операционной команде быть ближе к разработчикам, в варианте, когда конфигурация хранится в репозитории доступном обеим командам, т.к. разработчики лучше знают какие версии пакетов и библиотек необходимы для работы приложения, в какие конфигурационные файлы нужно внести изменения, а операционная команда должна, например, в кратчайшие сроки восстановить работоспособность приложения, в случае, возникновения проблемы, в том числе, путем пересоздания окружения, т.е. развернуть ВМ, ОС, необходимые системные пакеты и само приложение.

### 1.2.3 IaC tooling: Vagrant, Packer, Terraform, Ansible

давайте перейдем к теме инструментов в IaC. И перечислим задачи которые выполняет CM.
Шаблонизирование или темплейтинг инфраструктуры. Здесь подразумевается создание шаблона виртуальной машины, или имиджа контейнера, из которого будет развернут контейнер.
Созданные имиджи на первом шаге можно развернуть в облаке, т.е. из шаблона виртуальной машины запустить новую виртуальную машину в инфраструктуре облачного провайдера или развернуть приложение в системе оркестрации контейнеров
Далее, когда инфраструктура в виде виртуальных машин или контейнеров готова, становится возможна установка разрабатываемого или тестируемого приложения
и его конфигурация. эти четрые задачи можно выполнить разными инструментами, например,

![Сonfiguration management](../assets/01_59.png?raw=true "Сonfiguration management")

Есть такие утилиты как : puppet, saltstack, chef и A, которые закрывают большую часть представленного на слайде стека задач. С помощью их мы можем создать ВМ, внести изменения в конфигурацию ОС, например, изменить тайм зону, создать пользователя, от имени созданного пользователя установить необходимое ПО для работы разрабатываемого приложения и установить само приложение. Эти утилиты так или иначе одинаковы по своей архитектуре, разницу можно увидеть в Pull или Push модели

![Сonfiguration management](../assets/01_60.png?raw=true "Сonfiguration management")

В первом случае есть сервер управления, который распространяет конфигурацию на целевые машины, это модель PUSH,
Во второй модели, на целевых машинах установлены агенты, клиентское приложение, которые подключаются к серверу управления, для получения конфигурации, которую нужно установить на целевые машины. Это PULL модель.

![Сonfiguration management](../assets/01_61.png?raw=true "Сonfiguration management")

С точки зрения интереса к использованию, например здесь на Гугл Трендах графике можно увидеть что к А (это синий график) интерес в использовании растет.

![Сonfiguration management](../assets/01_62.png?raw=true "Сonfiguration management")

Если провести сравнение в звездочках на гитхабе, можно увидеть, что Ансибл сильно впереди в сравнении с другими. 

В дополнение к этим рассмотренным утилитам есть еще Vagrant – который является оберткой или дополнением к системам виртуализации (гипервизорам) и позволяет унифицировать процесс разработки. V позволяет создать шаблон виртуальной машины, запустить новую ВМ из этого имиджа и внести изменения во время первого запуска этой машины. 

![Сonfiguration management](../assets/01_63.png?raw=true "Сonfiguration management")

V идеально подходит для создания среды (или как их еще называют окружений) разработки, на которых разворачивается приложение.
Например, в случае, когда разработка ведется на различных ОС, например, у разработчиков есть ноутбуки с Windows, Linux или MacOS процесс подготовки окружения к запуску будет один и тот же, не зависимо от ОС. V запустит новую виртуальную машину, используя нужный образ, до установит необходимое ПО, скопирует нужные конфигурационные файлы. Т.о. У всех будет одинаковые версии ОС, пакетов и конфигурационных файлов на собственных окружениях для разработки установленные автоматически, а не в ручную каждым разработчиком по инструкции на вики.
Это значительно упрощает процесс разработки, особенно, если такие окружение нужно часто пересоздавать заново, в процессе работы.
Без использования V статья на вики для создания окружения могла выглядеть как инструкция о том, куда в интернете нужно зайти, чтобы скачать нужный инсталлятор, в какие файлы в нем нужно внести какие изменения.
В V эти действия представлены в виде кода:

![Сonfiguration management](../assets/01_64.png?raw=true "Сonfiguration management")

![Сonfiguration management](../assets/01_65.png?raw=true "Сonfiguration management")

Где в строке config.vm.box указано какой имидж для виртуальной машины нужно использовать, далее, после того как ВМ запустилась, 
указано, что нужно запустить скрипт runme.sh и если ВМ запущена в virtulbox то для нее нужно выделить 2Гб ОЗУ.
т.о. V помогает нам хранить знание об инфраструктуре в виде кода, его можно хранить в репозитории и быстро развернуть и не тратить время на ручной запуск и конфигурацию. 

Далее давайте поговорим о Terraform, с мощью его также можно управлять инфраструктурой.

![Сonfiguration management](../assets/01_66.png?raw=true "Сonfiguration management")

![Сonfiguration management](../assets/01_67.png?raw=true "Сonfiguration management")

Упрощенно, Задачу Terraform – можно представить как запись в виде кода инфраструктуры, созданнной вручную в веб-консоли администрирования облаком. Например, мы зашли в веб-консоль управления облаком, выбрали создание ВМ, далее, указали какие ресурсы в виде процессора, памяти и дисков, необходимо выделить, какой имидж ОС использовать и T сохранил информацию об этой ВМ в виде кода. 
Так же с помощью T возможно создавать и вносить изменения в инфраструктуру не пользуясь веб-консолью администрирования облака, где нужно переходить по различным меню, и вводить значения, а хранить эти значения в виде кода в репозитория.
Давайте наглядно посмотрим как работает Т,

![Сonfiguration management](../assets/01_70.png?raw=true "Сonfiguration management")

Все облачные провайдеры предоставляют API (application programming interface) через который возможно взаимодействовать с инфраструктурой которую мы арендуем. Например мы можем создать соотвествующий запрос, отправить его на определенный URL и создать виртуальную машину не заходя на веб-интерфейс администрирования.
Для того, чтобы работать с облачными провайдерами существуют
Клиентские библиотеки, которые позволяют формировать такие запросы в виде кода и они предоставляют 
T возможность управления инфраструктурой в облаке. Код который написан для Т называется HCL HashiCorp Configuration Language

![Сonfiguration management](../assets/01_71.png?raw=true "Сonfiguration management")

На этом слайде представлен простой пример кода Т, который в облаке АВС создает инстанс.
Парметр ami указаывает какой шаблон ВМ будет использован, далее указывается - размер ресурсов используется t3.micro, 
Расположение ВМ выбрано в eu-central-1a зоне и присвоен тэг sandbox.

Providers (конкретное облако - GCP, DO, AWS, YANDEX и др.)
Предоставляют набор ресурсов для управления 
Содержат настройки аутентификации и подключения к платформе или сервису

Resources
Определяются типом провайдера
Позволяют управлять компонентами платформы или сервиса
Могут иметь обязательные и необязательные аргументы Могут ссылаться на другие ресурсы
Комбинация тип ресурса + имя уникально идентифицирует ресурс в рамках данной конфигурации

![Сonfiguration management](../assets/01_72.png?raw=true "Сonfiguration management")

Можно сказать что Т – является стандартом по умолчанию для облачных провайдеров, так же существуют другие утилиты как Pulumi и Cloudfront концептуально похожие на Т, предназначение которых – описание с помощью кода инфраструктуры в облаке.
Ключевое отличие между этими утилитами для управления инфраструктурой и например А, который так же может быть использован для создания инфраструктуры будет то, что код запущенный А, каждый раз будет создавать новую виртуальную машину, а код запущенный на Т создаст одну виртуальную машину, и если его запустить повторно, просто проверит наличие существования этой машины. В этом ключе, имеет смысл использовать связку Т + А распределив задачи так, что Т создает ВМ, а А занимается ее провижинингом, т.е. Устанавливает необходимое ПО и копирует конфигурационные файлы, например.

Следующей утилитой, о которой мы упомянем при описании инфраструктруры – это Packer, так же как Terraform и Vagrant, разработанный компанией HashiCorp.

![Сonfiguration management](../assets/01_73.png?raw=true "Сonfiguration management")

Основная задача Paсker – это создание эталлонных шаблонов виртуальных машин, т.н. Golden-Images. и сохранение знания о том, какие и кем изменения вносились в эти шаблоны. Для создания шаблона P может использовать оригинальный образ от производителя ОS, он подключается к вашему облаку, на основе этого оригинального образа P создает новый инстанс заданного размера, указанным образом настраивает его и сохраняет как шаблон в вашей коллекции в облаке. Все это знание хранится в виде кода. Без исползования P, создание шаблона приходилось делать вручную, через консоль администрирования облаком, и занимало много времени + сохранение знания о том, какие изменения были внесены, приходилось вести вручную, например в текстовом файле или в статье на вики.

![Сonfiguration management](../assets/01_74.png?raw=true "Сonfiguration management")

Следующая и последняя на сегодня утилита, о которой поговорим – это cloud-init. его задача -

![Сonfiguration management](../assets/01_75.png?raw=true "Сonfiguration management")

– кастомизировать созданный инстанс в облаке,
Что это значит? Когда мы создаем инстанс, мы создаем его из имеющегося шаблона и его надо к-л образом настроить под определенный проект или клиента, например, создать пользователя с правами рута, выставить тайм-зону в ОС, скачать конфиг файл из репозитория. Все эти действия относятся к однократно выполняющимся операциям после первого запуска инстанса.

![Сonfiguration management](../assets/01_76.png?raw=true "Сonfiguration management")

![Сonfiguration management](../assets/01_77.png?raw=true "Сonfiguration management")

И в завершении рассмотрения инструментов в СМ обратим внимание, что для установки и конфигурации приложения на ВМ используется упоминавшиеся в самом начала утилиты на примере А. В том числе для устранения проблем с безопасностью, при обновлении пакетов до новых версий. В случае если мы контейнезировали наше приложение,


![Сonfiguration management](../assets/01_78.png?raw=true "Сonfiguration management")

И разместили его в системах оркестрации контейнеров : опеншифт и кубернетис для управления развертыванием нашего приложения могут потребоваться специальные утилиты, например helm, о которых говорилось в рамках занятий по облакам, и по своему содержанию эти утилиты тоже будут кодом, который хранится в репозитории.

Подводя итог теме про инструменты, еще раз резюмирую, что все что делается в ручную в консоли администрирования в браузере можно представить в виде кода в репозитории, и здесь нужно понимать ответственность при работе с IaC, где ошибка в файле может привести к неисправности на продакшен серверах. Для избежания таких ситуаций используются теже практики, что и для разработки ПО, например код ревью, парное программирование, мердж-реквесты, тестирование кода, и др.

![Сonfiguration management](../assets/01_79.png?raw=true "Сonfiguration management")

давайте перейдем к последней на сегодня теме, она будет не такая большая как про тулинг, но описывает понимание двух подходов используемых в CM 

### 1.3 Immutable infrastructure

Как мы уже говорили в предыдущей теме, когда мы создаем виртуальные машины в инфраструктуре мы можем использовать одни инструменты для создания самих виртуальных машин, например T и Другие инструменты для их конфигурации или провижининга – например А. и в процессе работы А, наш сервер мутирует, т.е. Изменяет свою конфигурацию, все дальше и дальше от оригинальной конфигурации, установленной Т. 
Такой подход называется Mutable infrastructure. Например, мы обновляем версию java на сервере, запускаем определеный А плейбук, затем, с помощью другого плейбука мы меняем какой-то пакет в системе на другой, потому что, например, разработчики хотят попробовать другой фреймворк для разработки приложения. И может случиться так, что кто-то внес иземения прямо на сервере, и А ничего об этом не знает. Такое имеет место быть, такое случается и это называется Configuration drift. При этом в репозитории гита эти изменения не видны. 
А мы, например разворачиваем, по просьбе разработчиков, еще дополнительные сервера и приложение на них уже не работает, т.к. Там нет некоторых, вручную внесенных изменений на старых серверах.
Mutable infrastructure – такой подход используется, когда в проекте нет возможности управлять созданием виртуальных машин.

![Сonfiguration management](../assets/01_83.png?raw=true "Сonfiguration management")

Есть и другой, подход – Immutable infrastructure где, например, с помощью P и А собирается шаблон ВМ

![Сonfiguration management](../assets/01_85.png?raw=true "Сonfiguration management")

Затем этот шаблон виртуальной машины используется Т для создания новой виртуальной машины на серверах. Такии образом, на каждое изменение инфраструктуры создается новый имидж, который хранит историю изменений и может быть развертнут на новом сервере точ в точ, как на уже имеющемся.

На этом, наверное, на сегодня по введению в IaC это все, что было подготовлено.

В завершении хочется резюмировать что IaC позволяет автоматизировать и ускорить создание и изменение в инфраструктуре но, сам по себе код,
Просто размещенный в репозитории не является IaC, и с использованием IaC приходит и большая ответственность за инфраструктуру.
Перейдем ближе к практической части

### 1.4 Training environment

Поговорим об нашему учебном окружении. Непосредственно с кодом мы предлагаем работать с VS Code. В блоге Льва можно ознакомиться где скачать VS Code, подсмотреть насройки SSH для подключения к окружению и выбрать рекомендуемые плагины. Само окружение у нас будет на виртуальной машине на Virtual Box, развернутое локально на лептопе. Для развертывания ВМ мы предлагаем использовать уже знакомый нам, тул из IaC – VAGRANT, он помогает нам быстро содать ВМ с необходимыми инструментами для работы над ДЗ, с помощью VS Code подключаемся к этой машине и ведем разработку кода. 
Давайте посмотрим как это все у нас работает,

![Сonfiguration management](../assets/01_88.png?raw=true "Сonfiguration management")

Интро в V мы уже сегодня сделали, теперь рассмотрим подробней V. Он установлен у нас локально на лептопе, здесь же у нас склонирован репозиторий с кодом
V создает виртуальную машину, репозиторий монтируется внутрь ВМ, в нашем случае c помощью vboxsf (VirtualBox SharedFolders) затем, V устанавливет А на ВМ
А устанавливаеся в локальном режиме на ВМ, т.е. Далее он провижинит сам себя, т.е. работает с тем же хостом, на котором установлен сам, А использует код из репозитория и устанавливает необходимое ПО для нашего учебного окружения.
И к этому окружению мы подключаемся VS Code. В итоге мы получили воспроизводимое окружение для работы, создали его через IaC. Если что-то у нас пойдет не так, внтутри ВМ, например, случайно удалили файл, внесли изменения в конф файл, хотим откатить изменения, но у нас нет бекапа, мы можем автоматически развернуть окружение снова и начать с начала. На этом про окружение все,

![Сonfiguration management](../assets/01_94.png?raw=true "Сonfiguration management")


